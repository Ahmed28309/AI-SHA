#!/usr/bin/env python3
"""
STT Node - Faster-Whisper Medium (GPU Accelerated)
Memory-efficient real-time speech recognition
Uses ReSpeaker mic array on Jetson Orin Nano
Publishes to /speech/text topic for LLM consumption
"""

import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import sounddevice as sd
import numpy as np
import threading
import queue
import time
from faster_whisper import WhisperModel


class STTNode(Node):
    def __init__(self):
        super().__init__('stt_node')

        # Parameters
        self.declare_parameter('sample_rate', 16000)
        self.declare_parameter('channels', 1)
        self.declare_parameter('chunk_duration', 1.0)
        self.declare_parameter('silence_threshold', 0.015)
        self.declare_parameter('model_size', 'medium')  # medium for accuracy, small for speed
        self.declare_parameter('device_index', -1)
        self.declare_parameter('language', 'en')

        self.sample_rate = self.get_parameter('sample_rate').value
        self.channels = self.get_parameter('channels').value
        self.chunk_duration = self.get_parameter('chunk_duration').value
        self.silence_threshold = self.get_parameter('silence_threshold').value
        self.model_size = self.get_parameter('model_size').value
        device_idx = self.get_parameter('device_index').value
        self.device_index = None if device_idx == -1 else device_idx
        self.language = self.get_parameter('language').value

        # Publisher - CORRECT TOPIC for LLM
        self.text_pub = self.create_publisher(String, '/speech/text', 10)

        # Audio queue
        self.audio_queue = queue.Queue()

        # Model loading
        self.model = None
        self.model_loaded = threading.Event()

        # Find ReSpeaker
        self._find_respeaker()

        # Load model in background
        self.get_logger().info(f'Loading Faster-Whisper {self.model_size} model...')
        threading.Thread(target=self._load_model, daemon=True).start()

        # Start audio processing thread
        threading.Thread(target=self._process_audio, daemon=True).start()

        # Start audio stream
        self._start_stream()

    def _find_respeaker(self):
        """Auto-detect ReSpeaker mic array"""
        if self.device_index is not None:
            self.get_logger().info(f'Using device index: {self.device_index}')
            return

        devices = sd.query_devices()
        for idx, device in enumerate(devices):
            name = str(device.get('name', '')).lower()
            if 'respeaker' in name or 'seeed' in name or 'ac108' in name:
                self.device_index = idx
                device_info = sd.query_devices(idx)
                max_channels = int(device_info.get('max_input_channels', 1))
                self.get_logger().info(
                    f'Found ReSpeaker: {device["name"]} (index {idx}, {max_channels} channels)')
                return

        self.get_logger().warn('ReSpeaker not found, using default mic')
        self.device_index = None

    def _load_model(self):
        """Load Faster-Whisper model (memory-efficient, works alongside LLM)"""
        try:
            # Try CPU first (more reliable on Jetson with limited GPU memory)
            self.get_logger().info('Loading model on CPU (avoids GPU memory conflict with LLM)...')
            try:
                self.model = WhisperModel(
                    self.model_size,
                    device="cpu",
                    compute_type="int8",
                    num_workers=4  # Use multiple CPU cores
                )
                device_name = "CPU"
                self.get_logger().info(f'Faster-Whisper {self.model_size} ready on CPU with int8 quantization')
            except Exception as cpu_error:
                self.get_logger().warn(f'CPU loading failed: {cpu_error}, trying GPU with smaller memory...')
                # Try GPU with minimal memory footprint
                self.model = WhisperModel(
                    self.model_size,
                    device="cuda",
                    compute_type="int8_float16",  # Hybrid mode for less GPU memory
                    num_workers=1
                )
                device_name = "GPU"
                self.get_logger().info(f'Faster-Whisper {self.model_size} ready on GPU with int8_float16')

            # Quick warmup
            dummy_audio = np.zeros(self.sample_rate * 2, dtype=np.float32)
            _ = list(self.model.transcribe(
                dummy_audio,
                language=self.language,
                beam_size=1,
                vad_filter=False
            ))

            self.model_loaded.set()
            self.get_logger().info(f'Model warmup complete. Ready for inference.')
            self.get_logger().info(f'Expected latency: 2-4s per utterance (medium model, accurate)')

        except Exception as e:
            self.get_logger().error(f'Model load failed: {e}')
            import traceback
            self.get_logger().error(traceback.format_exc())

    def _audio_callback(self, indata, frames, time_info, status):
        """Callback for audio stream"""
        if status:
            self.get_logger().warn(f'Audio status: {status}', throttle_duration_sec=5.0)
        self.audio_queue.put(indata.copy())

    def _start_stream(self):
        """Start continuous audio capture"""
        chunk_samples = int(self.sample_rate * self.chunk_duration)

        try:
            # Try single channel first
            try:
                self.stream = sd.InputStream(
                    device=self.device_index,
                    channels=self.channels,
                    samplerate=self.sample_rate,
                    blocksize=chunk_samples,
                    callback=self._audio_callback
                )
                self.stream.start()
                self.get_logger().info(f'Recording: {self.sample_rate}Hz, {self.channels}ch')
                return
            except Exception:
                # Fallback with channel mapping
                if self.device_index is not None:
                    device_info = sd.query_devices(self.device_index)
                    max_channels = device_info['max_input_channels']
                    self.get_logger().info(
                        f'Retrying with channel mapping from {max_channels}ch device')

                    self.stream = sd.InputStream(
                        device=self.device_index,
                        channels=1,
                        samplerate=self.sample_rate,
                        blocksize=chunk_samples,
                        callback=self._audio_callback,
                        dtype='float32'
                    )
                    self.stream.start()
                    self.get_logger().info(f'Recording: {self.sample_rate}Hz, 1ch')
                else:
                    raise

        except Exception as e:
            self.get_logger().error(f'Stream start failed: {e}')

    def _is_speech(self, audio_chunk):
        """Voice activity detection"""
        rms = np.sqrt(np.mean(audio_chunk**2))
        return rms > self.silence_threshold

    def _process_audio(self):
        """Process audio chunks from queue"""
        buffer = []
        silence_count = 0
        max_buffer_chunks = 25  # ~25 seconds
        min_speech_chunks = 2   # Minimum chunks
        required_silence_chunks = 2  # 2 seconds silence

        while rclpy.ok():
            try:
                chunk = self.audio_queue.get(timeout=0.5)

                if self._is_speech(chunk):
                    buffer.append(chunk)
                    silence_count = 0

                    if len(buffer) >= max_buffer_chunks:
                        self._transcribe_buffer(buffer)
                        buffer = []
                else:
                    if buffer:
                        silence_count += 1
                        if silence_count >= required_silence_chunks and len(buffer) >= min_speech_chunks:
                            self._transcribe_buffer(buffer)
                            buffer = []
                            silence_count = 0

            except queue.Empty:
                if buffer and len(buffer) >= min_speech_chunks:
                    self._transcribe_buffer(buffer)
                    buffer = []
                continue
            except Exception as e:
                self.get_logger().error(f'Process error: {e}', throttle_duration_sec=5.0)

    def _transcribe_buffer(self, buffer):
        """Transcribe accumulated audio buffer using Faster-Whisper"""
        if not self.model_loaded.is_set():
            return

        try:
            # Concatenate buffer
            audio = np.concatenate(buffer).flatten()

            # Convert to float32
            if audio.dtype != np.float32:
                audio = audio.astype(np.float32)

            # Transcribe with Faster-Whisper
            start_time = time.time()

            # Use medium model with better settings for accuracy
            segments, info = self.model.transcribe(
                audio,
                language=self.language,
                beam_size=3,  # Increased for better accuracy
                vad_filter=True,  # Voice activity detection
                vad_parameters=dict(
                    min_silence_duration_ms=500,
                    threshold=0.5
                ),
                temperature=0.0,
                condition_on_previous_text=False,
                compression_ratio_threshold=2.4,
                log_prob_threshold=-1.0,
                no_speech_threshold=0.6
            )

            # Collect all segments
            text_segments = []
            for segment in segments:
                text_segments.append(segment.text)

            elapsed = time.time() - start_time
            text = ' '.join(text_segments).strip()

            if text:
                # Publish
                msg = String()
                msg.data = text
                self.text_pub.publish(msg)

                self.get_logger().info(f'"{text}" ({elapsed:.2f}s)')

        except Exception as e:
            self.get_logger().error(f'Transcription failed: {e}', throttle_duration_sec=5.0)
            import traceback
            self.get_logger().error(traceback.format_exc())

    def destroy_node(self):
        """Cleanup on shutdown"""
        if hasattr(self, 'stream'):
            self.stream.stop()
            self.stream.close()
        super().destroy_node()


def main(args=None):
    rclpy.init(args=args)
    node = STTNode()

    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
